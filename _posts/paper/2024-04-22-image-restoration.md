---
layout: post
title: 图像修改工作进展
category: 文献阅读
keyworks: image processing, image restoration
tags: 图像修改、图像修复
---

# 图像处理相关技术进展总结

> A briefly survey on image processing， including image restoration

图像处理作为计算机视觉中的重要基础任务，在很多应用场景中都有应用。典型的图像处理应用包括：图像修复、图像复原、图像补全、超分辨率、运动去模糊等。



# [2023ICCV] DiffIR: Efficient Diffusion Model for Image Restoration



### 研究背景

1. 如果将以图像合成为主的扩散模型应用到图像复原的任务中，那么不仅会浪费大量的计算资源，而且容易生成与低质量图片（LQ）图像不匹配的细节。
2. 因为图像复原任务中，很多像素是一直的，所以没有必要在整个图像或特征上使用DM。

### 研究思路

由于transformer可以建模长程像素依赖，所以作者采用transformer块作为DIFFIR的基础模块。作者在UNet结构中堆叠tranformer以构建Dynamic IRformer，以提取和聚集多尺度特征。作者采用双阶段训练方法：（1）在第一阶段，作者开发了一个紧凑的IR先验提取网络CPEN从真实图像中来提取紧凑的IR先验表示IPR，以指导DIRformer。此外，开发了一个dynamic gated feed forward network(DGFN)和dynamic multi head transposed attention(DMTA) 以充分地利用IPR。 值得注意的是，CPEN和DIRformer是一起训练的。（2）在第二阶段，训练一个扩散模型从LQ图像中直接预测准确的IPR。因为IPR是轻量化的，并且仅需添加细节来修复图像，作者提出的DM可以相当准确的估计IPR，并且在几次迭代以后就能获得稳定的视觉效果。

除此之外，作者指出联合优化可以有效提升效果。



# [2022CVPR、LDM] High-Resolution Image Synthesis with Latent Diffusion Models

#### 摘要

通过将图像信息过程分解成去噪自编码器的序列应用，扩散模型在合成图像数据上取得了SOTA的结果。此外，这些信息允许在不重新训练的情况下，利用引导机制来控制图像生成过程。然而，这些模型大多直接在图像空间中操作，优化一个强大的DM通常需要消耗数百个GPU天，并且由于序列评估推断的开销非常昂贵。为了使DM在有限计算资源但是保持它们高质量和灵活性，我们将他们应用到强大的预训练自编码器的潜在空间。与现有工作不同，在这种表示上训练的扩散模型能够达到复杂性降低和细节保留的近优点。通过在模型结构中引入交叉注意力层，作者将DM变成更加强大和灵活的生成器，允许使用文本或边界框作为条件输入，以卷积的方式实现高分辨率的合成。作者提出的LDM在图像修复和类别图像合成取得了SOTA的性能，在不同任务上也取得了较高的性能，如无条件图像生成，文本到图像合成，超分辨率，同时与基于像素的DM先比，计算量减少了很多。

#### 1 研究背景

现有的DM方法存在一些问题：

+ DM的模态覆盖行文会使得她们花费大量的能力在建模型数据的细节上。
+ DM计算消耗非常大，因为训练和评估这样的模型都需要在高维地RGB空间中反复地函数评估和梯度计算。如训练最强大的DM模型通常需要耗费150-1000个V100天，反复评估输入空间渲染的噪声版本同样非常昂贵，使用一个A100GPU产生50k个样本大约需要花费5天。

对研究社区和用户会照成以下威胁

+ 训练这样的模型需要大量的资料，只局限于少数有能力的选手，同时会留下大量的碳排放。
+ 评估这样训练好的模型在时间和内存上同样非常昂贵，因为相同模型结果必须大量的串行运行。

因此，**在不影响她们性能的情况下，减少DM的的计算需求，是增强它们易得到性的关键。**

**转入潜在空间** 对于任意一个基于似然的模型，学习都可以分成两个阶段：

+ 第一阶段是感知压缩阶段，即移除高频细节，但会学习少量语义变化。
+ 在第二阶段，实际的生成模型学习数据（语义压缩）的语义和概念化。

作者旨在找到一个感知等价，但是计算更加友好的空间，这样就能够生成高分辨率的图像。

具体而言，作者按照以往的常见实践，将训练分成两个不同的阶段：

+ 首先，训练了一个自编码器，它能提供一个低维（因此有效）的表示空间，这与数据空间的感知等价。重要的是，作者没有依赖大量的空间压缩，因为作者在学习的潜在空间中训练DM，这展示出与空域维度很好很好的缩放属性。降低的复杂性还通过单个网络通信从潜在空间中提供高效的图像生成。
+ 所提方法的重要优势在于只需训练一个通用的自编码器，因此可以在后续DM训练中可以重用，并且可以用在不同的任务中。因此，作者采用了一个UNet结构的DM网络结构，这支持任意类型的基于令牌的调节机制。

因此，本文的贡献如下：

+ 与完全基于transformer的方法相比，本文的方法可以更加优雅地拓展到更高维度，因此（a）可以在压缩级别上工作，提供比以前的工作更加详实和详细的重建效果。（b）可以应用到生成百万像素及别的高分辨率合成上。
+ 在大多数任务和数据集上，以更低的计算代价取得了较好的结果，包括无条件图像生成，图像补全，随机超分辨。与现有基于像素的扩散方法相比，本方法的推理时间更短。
+ 与现有的同时学习编码器和解码器结构以及得分先验的方法相比，本文方法无需对重建或生成能力进行微妙的权衡。这确保了极其忠实的重建，并且几乎不需要对潜在空间进行正则化。
+ 本文发现密集条件任务如超分辨率，图像补全，语义合成，本文的模型可以以卷积的方式应用，并渲染~1024分辨率。
+ 此外，作者设计了一种基于交叉注意力的通用条件控制机制，使多模态训练变得可能。作者用其实现类条件，文本到图像以及布局到图像模型。
+ 最终，作者公布了潜在扩散模型以及自编码器模型 `https://github.com/CompVis/latent-diffusion`

#### 2 相关工作

##### 图像合成的生成模型

+ GAN以高的感知质量高效地采样高分辨率地图像，但是很难优化，并且很难捕获全部地数据分布。
+ 基于似然的方法强调良好的密度估计，这使得优化更加良好。
+ 变分自编码器和流模型在高分辨率图像的高效生成上更加优势，但是采样质量不如GAN。
+ 自回归模型（ARM）在密度估计上非常有优势，计算要求高的架构，且序列采样过程限制它们在赌低分辨率图像。因为基于像素的图像表示包含几乎无法察觉的高频细节，最大似然训练在建模上花费了不成比例的容量，导致长时间的训练。
+ 为了扩展到高分辨率，一些双阶段方法使用自回归模型来建模一种压缩潜在图像空间，而不是像素空间。

##### 扩散概率模型（DM）

DM在密度估计和图像质量上取得了SOTA的结果。这些模型的生成能力源自于对图像数据引导偏差的自然拟合，当他们现在的神经网络骨架是由UNet实现时。最佳的合成质量通常是由重新赋权的目标函数指导的训练获得的。在这种情况下，DM类似于有损压缩器，使得可以在图像质量和压缩能力之间实现平衡。

然而，在像素空间评估和优化这些模型，推理速度很慢，并且训练代价很高。针对第一个问题，可以采用一些先进的采样策略和层级方法，在高分辨图像数据上训练通常需要计算昂贵的梯度。作者提出LDM来解决这个问题，该方法在低维的压缩潜在空间工作。这使得训练代价更加便宜，在图像质量不降低的情况下推理速度更快。

##### 两阶段图像合成

为了消除单生成方法的缺点，大量的研究者探索通过双阶段方法，研究结合不同方法的长处实现更加高效和高质量的模型。VQ-VAE使用自回归模型在离散潜在空间中学习一个具有表示性的先验。此方法也被应用到文生图的任务中，通过学习离散图像和文本表示的联合分布。VQGAN在第一阶段使用对抗和感知目标函数将自编码器transformer拓展到更大的图像。然而，高压缩率需要可行的自回归模型的训练，这导致大量的训练参数，限制的了该方法的应用，更少的压缩是以高计算成本为代价的。

作者的方法避免了这个问题，因为LDM的卷积骨架的原因，它能以更加温和的方式扩展到更高维的潜在空间。因此，作者可以自由地在第一阶段以最优地方式学习强大地压缩率水平，而不会在生成扩散模型中留下过多地感知压缩，同时保证高保真度的重建。尽管本文方法需要利用基于得分先验对编码器和解码器进行联合学习，他们同样需要在重建和生成能力复杂的权衡，因此优于本文方法。

#### 3 方法

为了降低在高分辨率图像合成中训练扩散模型的代价, 作者发现尽管通过对相应损失进行欠采样可以使扩散模型忽略无关的细节, 但他们还需要在像素空间进行复杂的评估， 这导致需要大量的计算时间和能源。

作者提出通过通过引入压缩学习阶段和生成学习阶段的明确分离来规避这个缺点。为实现这个目标，作者利用一个自编码器模型去学习一个空间，这个空间与图像空间感知等价，但是可以极大的减少计算复杂度。本文方法的优点有以下几点：

+ 通过利用高维图像空间，作者得到的扩散模型在低维空间上进行，因此计算效率更高。
+ 作者利用DM中UNet结构的诱导偏差，这使得它们处理空域结构数据上更加有效，因此缓解了过去方法对渐进性，质量下降压缩水平的问题。
+ 最终，作者得到了一个通用的压缩模型，该模型潜在空间可以用于训练多个生成模型，并且可以用于其他下游应用，如单图像CLIP引导合成。

##### 3.1  感知图像压缩

本文的感知压缩模型是基于以前的工作[23]，是由使用感知损失和基于补丁的对抗目标函数训练得到的自编码器。这保证了通过强制执行局部真实感来确保重建仅限于图像流形，从而避免了由于仅依赖像素空间损失如L2或L1目标函数导致的模糊问题。

给定一张RGB空间的图片$x\in R^{H \times W \times 3}$，编码器E将图像x编码到潜在表示$z=E(x)$, 解码器D从该潜在表示重建出图像，得到$\hat{x}=D(z)=D(E(x))$, 其中$z\in R^{h \times w \times c}$。重要的是，编码器以因子$f=H/h=W/w$下采样图像，本文将对不同的下采样因子$f=2^m$进行研究，其中$m \in N$。

为了避免潜在空间中过高的方差，作者尝试了两种不同的正则化。第一种是KL-reg，对学习的潜在施加KL惩罚，使其趋向标准正态分布。与VAE类似，即VQ-reg，在解码器中使用一个向量量化层。该模型可以解释为VQGAN，但是量化层在解码器中。由于本文的DM旨在处理学到的二维结构空间$z=E(x)$，因此可以使用相对温和的压缩率，并且取得非常好的重建结果。这与现有不同，这些方法依赖学到空间z的一个任意的1D次序以自回归地建模其分布，并因此忽略z的内在结构。因此，我们的压缩模型可以更好地保留x地细节。全部目标函数和训练席间见附录。

##### 3.2 潜在扩散模型（LDM）

**扩散模型**是概率模型，通过逐渐去除正太分布变量学习数据分布p(x)，这与学习固定长度T的马尔科夫链的逆过程类似。对于图像合成任务，当前最成功的模型都依赖p(x)的变分下限的重加权变体，这反应了去噪分数匹配。这些摸可以解释成一种等价的加权去噪自编码器$\epsilon_\theta(x_t,t); t=1...T$，训练用于预测输入$x_t$的去噪版本，其中$x_t$是输入x的噪声版本。对应的目标函数可以简化成
$$
L_{DM}=\mathbb{E}_{x,\epsilon\sim N(0,1),t}[||\epsilon - \epsilon_\theta(x_t,t)||_2^2]
$$
其中t是从{1,...,T}中均匀采样的。

**潜在表示的生成模型** 使用由编码器和解码器构成的训练好的感知压缩模型，可以得到一个高效的、低维的潜在空间，在这个空间中，高频的、难以察觉的细节被抽象出来。与现有的高维像素空间相比，本文提出的空间更适合基于似然的生成模型，因为（a）它们关注数据中重要的、语义位；（b）在低维空间，计算效率高的空间中训练。

不同于以前的依赖自回归的工作，基于注意力的transformer模型是高压缩的，离散的潜在空间，利用该图像特有的诱导偏差的优点是本文的重点。这包括从2D卷积层构建一个UNet结构的能力，并且使用重权重边界进一步关注感知最相关位，因此损失可以变成如下的形式
$$
L_{DM}:=\mathbb{E}_{E(x),\epsilon\sim N(0,1),t}[||\epsilon - \epsilon_\theta(z_t,t)||_2^2]
$$
模型的神经骨架$\epsilon_\theta(o,t)$由[69]提出的带时间条件的UNet实现。因为前向过程是固定的，在训练过程始中，$z_t$可以从编码器E中有效得到，并且使用一次解码器即可从采样p(z)中重建出图片。

##### 3.3 条件机制

与其他生成模型类似，扩散模型本质上是建模形为p(z|y)的条件分布。这可以通过条件去噪编码器$\epsilon_\theta(z_t,t,y)$并且通过输入y（如文本，语义图、或其他图像到图像的翻译任务）控制合成过程。在图像生成任务场景中，结合DM的生成能力，除类别标签外的条件或输入图像的模糊变体是尚未探究的研究领域。本文通过增加带交叉注意力机制的UNet骨架，将DM变成更加灵活的条件图像生成，这对于多输入模态的基于注意力模型非常有效。为了从不同模态预处理条件y（如语言prompt），作者引入了一种特定领域编码器$\tau_{\theta}$，将y投影到中间层表示$\tau_{\theta}(y)\in R^{M\times d_t}$，随后被通过交叉注意力层映射到UNet的中间层实现$Attention(Q,K,V)=softmax(\frac{QK^T}{\sqrt{d}})\cdot V$得到
$$
Q = W_Q^{(i)} \cdot \phi_i(z_t), K=W_k^{(i)}\cdot\tau_\theta(y), V=W_V^{(i)}\cdot\tau_\theta(y)
$$
其中，$\phi_i(z_t)\in R^{N\times d^i_\epsilon}$表示UNet展平的中间表示，后面几项是可学习的投影矩阵。详情如图3所示。

![image-20240423110309004](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20240423110309004.png)

基于图像条件对，本文的条件LDM表示如下：
$$
L_{DM}:=\mathbb{E}_{E(x),\epsilon\sim N(0,1),t}[||\epsilon - \epsilon_\theta(z_t,t,\tau_\theta(y))||_2^2]
$$
其中，$\tau_\theta$和$\epsilon_\theta$是由上式联合优化得到的。这个条件机制是灵活的，因为可以由领域专家进行参数化，如当y是文本prompt时的无masked transformer。

#### 4 实验

LDMs为灵活计算可处理的基于扩散的图像合成提供了手段，包括各种不同图像模型的高分辨率生成。首先，本文分析了在训练和推理阶段，与基于像素的扩散模型的收益。有趣的是，本文发现LDMs用VQ-reg训练的潜在变量可以获得更好的采样质量。尽管VQ-reg的重建能力在第一阶段模型稍微落后于其连续的版本cf， 表8。因此，除非另有说明，本文在后续均采用VQ-reg LDMs。附录提供了第一阶段正则化模式在LDM训练上和其泛化到更高分辨率$256^2$泛化能力。在附录D.2中，作者进一步列出了详细的结构、实现、训练和所有结果的验证信息。

##### 4.1 感知压缩的权衡

![image-20240425221602297](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20240425221602297.png)

本章分析了在不同下采样因子f∈{1，2，4，8，16，32}上LDM（简写为LDM-f）的行为，其中LDM-1表示基于像素的DM。为了进行公平的比较，作者将计算资源固定为单个A100，本章节所有的实验均在该资源上进行，以相同的迭代步骤和参数量训练所有的模型。

![image-20240425221639780](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20240425221639780.png)

![image-20240425221706669](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20240425221706669.png)

表8展示了LDM所使用的第一阶段模型在超参数和重建性能。图5展示了ImageNet类条件下在2M次训练过程的样本质量。可以看出，

+ 更小的下采样因子LDM-{1，2}会导致很慢的训练过程
+ 过大的f会导致几个训练步骤以后保证度的停止更新（如图1和图2）。

通过上述的分析，作者认为造车这个现象的原因是：

+ 将大部分感知压缩留给扩散模型
+ 第一阶段压缩太强会导致信息的丢失，从而难以取得更高的质量。

LDM-{4-16}在有效性和感知忠诚度结果方面取得了平衡，在FID指标方面呈现出很大的优势。在2M次训练后，基于像素的扩散模型（LDM-1）和LDM-8在FID方面的指标差异为38。

![image-20240425221620770](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20240425221620770.png)

在图6中，我们应用DDIM采样器，比较了在CelebA和ImageNet上训练的模型上，不同去噪步骤采样速度的差异。LDM-{4-8}优于感知和感念压缩比例不合适的模型。特别是与基于像素的模型LDM-1相比，取得了更低的FID得分，同时极大地提高了采样速度。**复杂的ImageNet数据集需要减少压缩率，以避免质量的下降**。总而言之，LDM-4和LDM-8在取得高质量合成结果上取得了最佳的结果。疑问：如何衡量压缩率，是通过f来控制的吗？

##### 4.2 使用潜在扩散的图像生成

本文在CelebA-HQ, FFHQ, LSUN-Churches和Bedrooms数据上训练了分辨率为256的无条件模型。并评估在采样质量和对数据流行的覆盖率，分布使用FID和Precision-and-Recall。表1列出了结果。结论如下：

+ 在CelebA-HQ上，本文取得了新的SOTA 5.11，优于以前的基于似然的模型和GAN。同样的，优于LSGM，这个一个联合第一阶段的潜在扩散模型。
+ 在固定的空间训练扩散模型，避免了权重重建质量和在潜在空间学习先验的困难。
+ 在LSUN-Bedroom数据集上，优于基于先验的扩散的数据集，得分类似于ADM，尽管只利用了其一般的参数以及1/4的训练资源。
+ 在P-R上，LDM一致地优于基GAN地方法，因此证明了基于似然方法的态覆盖率优于对抗方法。在图4中，本文展示了在每个数据集上的定性结果。

##### 4.3 条件潜在扩散

##### 4.3.1 用于LDM的transformer编码器

通过将基于交叉注意力的条件控制器引入LDM，本文开启了以前工作没有踏足的多条件模态。对于文本转图像的图像建模，本文在LAION-400M数据集上训练了一个以语言prompt为条件的1.45B参数量的模型。本文利用BERT-tokenizer以及将$\tau_\theta$实现为一个transformer以将其转换成潜在编码，该过程由交叉注意力引入UNet模型中。领域特定专家知识的引入构建一个强大的模型以学习自然语言表示并且视觉合成结果，使其能很好的泛化到复杂，用户定义的文本prompt中。

##### 4.3.2 超过256分辨率的卷积采样

通过在空间将条件信息拼接到$\epsilon_\theta$输入中, LDM可以成为一个有效的通用图像到图像的转换模型。作者将使用其实现语义合成，超分辨率，以及图像补全。分别介绍如下：

+ 语义合成：使用带有语义映射图的景观图像对，拼接由VQ-reg训练的LDM-4模型构建的语义映射图的下采样版本的潜在图像表示。本文在256分辨率的图像上训练（从384分辨率图像中裁剪得到），但是发现本文的模型可以泛化到更大的分辨率上，并且当以卷积方式评估时，可以生成高达百万像素的图像。
+ 超分辨率：LDM可以通过拼接以低分辨率图像为条件，从而有效地训练超分辨率。在第一个实验中，与SR3一样，将图像的退化程度固定为一个双线性插值下采样，并且按照SR3数据预处理的方式在ImageNet上进行训练。使用在OpenImage数据集上预训练的f=4的自编码器模型，并且拼接低分辨率条件y与输入到UNet模型上，其中$\tau_\theta$是恒等的。实验结果表明，本文方法在FID上优于SR3，但是SR3在IS上表现得更好的。从结果可以看出，一个简单的图像回归模型，可以取得更高的PSNR和SSIM得分。然而，这些指标却无法很好地反应人类感知，并且**文献[70]指出这些指标倾向于模糊而不是不完全对齐的高频细节。**作者发现由于双线性退化过程不能很好地泛化到到图像中（图像并不能很好地遵循这个预处理过程），通过使用更加多样的退化，本文又训练了一个通用模型，LDM-BSR。

![image-20240426080451397](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20240426080451397.png)

+ 图像修复。图像修复是用新内容填充图像的遮罩区域的任务，因为图像的某些部分已损坏，或者替换图像中现有的但是不需要的内容。作者评估了本文如何将用于条件图像生成的通用方法应用到更加专门的任务上。作者按照LaMa提出的评估准确，最近提出的一种依赖快速傅里叶卷积的用于图像修复的专门结构。本文将在Place数据集上进行评估。作者搜先分析了不同第一阶段设计的影响。作者对比了在不使用任何注意力的情况下，使用KL或VQ正则化的LDM-1和LDM-4的差异，VQ-LDM-4在高分辨率下能够有效地减少GPU显存。出于可比性，本文固定了所有模型的参数量。表5和表6给出了在256和512分辨率下的结果。

  ![image-20240426081542201](https://gitee.com/freeneuro/PigBed/raw/master/img/image-20240426081542201.png)

  表7结果表明使用了注意力的本文方法可以在整体上提升FID结果，无mask图像以及本文采样结果之间的LPIPS优于文献[85]。作者解释称：与LDM相比，文献[85]仅产生了单种结果，其倾向于回复更多平均图像的细节。

  #### 5 结论

  本文提出了潜在扩散模型，一种简单但是有效地的极大提升扩散模型训练和采样速度，而质量不会下降的方法。基于此，本文的交叉注意力条件机制可以支持不同的条件控制生成任务。

