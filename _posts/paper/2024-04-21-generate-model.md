---
layout: post
title: 生成模型的进展
category: 文献阅读
keyworks: generator model, GAN, VAE
tags: 生成模型, 生成对抗网络, 变分自编码器, 扩散模型
---

# 生成模型进展总结

> A briefly survey on classical generate model

生成模型作为是计算机视觉中的重要基础任务，支撑了很多下游应用。本文旨在简要总结近年来典型的生成模型的基本思想，以作记录便于回顾。



# 不同生成模型的优缺点

| 方法              | 优点                                                         | 缺点                                                         |
| :---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| AE                | 1. 压缩模型                                                  | 1. 中间特征表示能力弱，生成图像分布单一；                    |
| VAE               | 1. 多样性更好 ,比GAN易于扩展和训练<br>2.                     | 1. 采样图像的质量不高; <br>2. 推理时间不如GAN                |
| GAN               |                                                              | 1. 对参数敏感, 训练不稳定, 很难训练； <br>2. 生成的图像容易陷入模式坍塌, 即多样性差; |
| PixelCNN/PixelRNN | 1. 以自然语言的方式建模图像生成任务<br>以自回归的方式逐像素进行预测 | 1. 训练代价高；                                              |
| VQVAE             | 1. 将中间变量离散化，增强特征表示能力；<br>2. 采用梯度停止策略，有效解决离散中间变量的优化问题 | 1. 生成图像模糊                                              |
| VQGAN             | 1. 引入对抗和感知损失；<br>                                  |                                                              |
| VQGAN-CLIP        | 1. 引入对比学习策略，支持文本控制生成;<br>                   |                                                              |
| DDPM              | 1. 可生成高质量图片;<br>2.易于扩展, 分布覆盖率, 固定的训练目标; <br> | 1.需要大量的迭代次数，消耗的计算资源大；<br>2.               |
| DDIM              |                                                              |                                                              |
| LDM               | 1. 简单高效；<br>2. 覆盖更广泛的数据分布；<br>3. 引入交叉注意力机制，开辟了多模态条件控制生成的新时代；<br>4. 有效地应用到不同的领域 |                                                              |





# AE

参考资料：https://zhuanlan.zhihu.com/p/657857297

# VAE



参考资料：

+ https://www.cnblogs.com/amazingter/p/14686450.html#:~:text=AE%E4%B8%BB%E8%A6%81%E7%94%A8%E4%BA%8E%E6%95%B0%E6%8D%AE,%E5%88%99%E8%A6%81%E7%94%A8%E5%88%B0GAN%E3%80%82
+ https://spaces.ac.cn/archives/5253

# VQ-VAE



实现资料：https://zhuanlan.zhihu.com/p/640000410

参考资料：

+ https://zhuanlan.zhihu.com/p/388299884
+ https://zhuanlan.zhihu.com/p/633744455
+ https://www.spaces.ac.cn/archives/6760

# VQ-GAN



参考资料：

+ https://zhuanlan.zhihu.com/p/515214329

# VQGAN-CLIP



# Diffusion Model



# 重要相关文献

| 文献                                                         | 重要贡献                                                     | 重要观点                                                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 【NeurIPS2021】Diffusion Models Beat <br> GANs on Image Synthesis | 1. 提出了一种分类引导的有条件图像生成方法,该方法的在各分辨率下的FID为：<br>128*128：2.97，256\*256：4.59，512x512：7.72;<br>2. 作者在文中采用简单的均方误差损失和vlb损失组合的混合目标函数作为目标函数<br>, 以及参数化技巧, 从而在不降低图像质量的情况下获得了更快的采样速度<br>3. 采用类似于DDIM的方法, 通过改变逆向噪声的方差实现从任何步骤的去噪.<br>4. 模型改进: 除了缩放残差连接外, 增加注意力头的数量和尺寸, <br>使用BIGGAN的残差连接实现上采样和下采样均对结果有提升.<br>增加网络深度会增加训练时间代价;<br>每个注意力头中,  更多注意力头数和更少通道数, FID越高<br>5. 类引导: 在噪声图像训练一个分类器,然后使用分类器的梯度来引导扩散向类别标签y的采样过程. | 1.分类引导方法可以与上采样扩散模型很好地结合；<br>2. 扩散模型生成图像的质量优于同期SOTA的GAN模型；<br>3. 调整分类梯度的尺度可以好好地平衡多样性和保真度; 并且减少采样时间, 尤其是高分辨率的情况. <br> 4.作者认为DM不如GAN的原因有: <br>(1)GAN的结果经过大量的探索和设计; (2) GAN有能力平衡多样和保真度, 可以生成高质量图片但是无法覆盖整个分布<br>5.作者采用FID作为全文的指标, 是因为它能捕获保真度和多样性, 并且是SOTA生成模型的金标准. <br>使用PR来分别衡量保真度和多样性;<br>使用sFID来捕获空间关系<br>使用IS来评估保真度.<br>6. GAN在条件生成任务中, 严重依赖类别标签, 采用类条件归一化统计的形式. <br>但是有研究表明, 在类别数有限的情况下, GAN可以表现得较好<br>7. 召回率是用来评估分布覆盖率的. |

